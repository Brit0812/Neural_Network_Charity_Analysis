{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO68suhh2FVJEe8iDhzMCET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brit0812/Neural_Network_Charity_Analysis/blob/main/AlphabetSoupCharity_Optimzation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "NDCUhnw1nnbX",
        "outputId": "077edc1c-aa63-4073-cac5-352d5c1f88db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1308d74e-da4a-46a2-94f3-6b84b84541ac\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1308d74e-da4a-46a2-94f3-6b84b84541ac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving charity_data.csv to charity_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#importing the file from the comp to colab df=pd.read_csv(io.StringIO(data[\"file_name.csv\"].decode('utf-8')))\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "data=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df=pd.read_csv(io.StringIO(data[\"charity_data.csv\"].decode('utf-8')))\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "_R9UT80-pFzH",
        "outputId": "11d0dfbd-702e-48b1-be18-4f4462c071d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efeb0a47-2671-42bb-a4fd-53c361bf4f4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efeb0a47-2671-42bb-a4fd-53c361bf4f4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efeb0a47-2671-42bb-a4fd-53c361bf4f4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efeb0a47-2671-42bb-a4fd-53c361bf4f4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(['EIN', 'NAME', 'USE_CASE', 'ORGANIZATION' ], axis=1, inplace=True)\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "vilvKCaSpJ6b",
        "outputId": "7cf52621-6350-486f-ef4f-0db6c5e7b895"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION  STATUS     INCOME_AMT  \\\n",
              "0              T10       Independent          C1000       1              0   \n",
              "1               T3       Independent          C2000       1         1-9999   \n",
              "2               T5  CompanySponsored          C3000       1              0   \n",
              "3               T3  CompanySponsored          C2000       1    10000-24999   \n",
              "4               T3       Independent          C1000       1  100000-499999   \n",
              "\n",
              "  SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0                      N     5000              1  \n",
              "1                      N   108590              1  \n",
              "2                      N     5000              0  \n",
              "3                      N     6692              1  \n",
              "4                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83825a5a-c176-44ad-b2bd-c9a2beb83a4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83825a5a-c176-44ad-b2bd-c9a2beb83a4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83825a5a-c176-44ad-b2bd-c9a2beb83a4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83825a5a-c176-44ad-b2bd-c9a2beb83a4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique values in each column.\n",
        "#ask_amount could be placed into buckets same with classification\n",
        "application_df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jhFnzJ4pQbt",
        "outputId": "836e6a6e-4b32-4f2b-de5c-6b90ba014709"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_type= application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR-F51piwLKM",
        "outputId": "4cf482cb-1c5a-485c-a1e9-1d725f457620"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which values to replace if counts are less than ...?- less than 500 theyll go into other. \n",
        "replace_application= list(application_type[application_type< 500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_application:\n",
        "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df.APPLICATION_TYPE.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85HuMPyUwJCP",
        "outputId": "98cf2a5d-dea3-42a3-aa09-21fe8c87a2b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "class_count= application_df[\"CLASSIFICATION\"].value_counts()\n",
        "class_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW7ytA4wwPwv",
        "outputId": "e87646c4-07a9-4438-9c42-238e4eb887e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which values to replace if counts are less than ..?--\n",
        "replace_class= list(class_count[class_count< 1500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in replace_class:\n",
        "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df.CLASSIFICATION.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIXE0IMhwS38",
        "outputId": "9653535b-cedd-4681-fe4e-05372e823061"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#binning\n",
        "ask_amt= application_df[\"ASK_AMT\"].value_counts()\n",
        "ask_amt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwZFgPzEpfac",
        "outputId": "7c770649-ccf1-4489-e3ef-cf4eac67bda8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000        25398\n",
              "10478           3\n",
              "15583           3\n",
              "63981           3\n",
              "6725            3\n",
              "            ...  \n",
              "5371754         1\n",
              "30060           1\n",
              "43091152        1\n",
              "18683           1\n",
              "36500179        1\n",
              "Name: ASK_AMT, Length: 8747, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_amt.plot.density()\n",
        "#values around 1 and 3?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "b0e0RK1BpknN",
        "outputId": "25284bf6-161b-436e-ab00-b009c9fdd5c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7bf0f6f610>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which values to replace if counts are less than ...?- less than 500 theyll go into other. \n",
        "replace_amt= list(ask_amt[ask_amt< 3].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for amt in replace_amt:\n",
        "    application_df.ASK_AMT = application_df.ASK_AMT.replace(amt,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df.ASK_AMT.value_counts()\n",
        "#a large part of the column is in the other bucket- this wont work\n",
        "#possibly making a range- bucketing the ranges?\n",
        "#test later "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjsUS_njppTo",
        "outputId": "e0fb2d1d-8c47-453a-df01-1860b35a2b03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000     25398\n",
              "Other     8889\n",
              "15583        3\n",
              "6725         3\n",
              "10478        3\n",
              "63981        3\n",
              "Name: ASK_AMT, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which values to replace if counts are less than ...?- less than 500 theyll go into other. \n",
        "replace_amt= list(ask_amt[ask_amt< ######].index)\n",
        "\n",
        "#how many clumps of amount asked should there be? \n",
        "#make a for loop to filter through and place it in the bucket? \n",
        "#\n",
        "# Replace in dataframe\n",
        "# for amt in replace_amt:\n",
        "    # application_df.ASK_AMT = application_df.ASK_AMT.replace(amt,\"Other\")\n",
        "# Check to make sure binning was successful\n",
        "application_df.ASK_AMT.value_counts()\n",
        "#skip for now- need to complete a for loop "
      ],
      "metadata": {
        "id": "lBYmp9ClFmX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate our categorical variable lists\n",
        "application_cat= application_df.dtypes[application_df.dtypes==\"object\"].index.tolist()\n",
        "application_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKUZocvfwClx",
        "outputId": "6ff4625e-a5a9-4bc9-d1f6-f7453abd6659"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['APPLICATION_TYPE',\n",
              " 'AFFILIATION',\n",
              " 'CLASSIFICATION',\n",
              " 'INCOME_AMT',\n",
              " 'SPECIAL_CONSIDERATIONS']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df= pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names(application_cat)\n",
        "encode_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "QRBG5Hbtwsoi",
        "outputId": "373b266d-957b-4787-e902-90297824bd3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
              "0                     0.0                   1.0                   0.0   \n",
              "1                     0.0                   0.0                   0.0   \n",
              "2                     0.0                   0.0                   0.0   \n",
              "3                     0.0                   0.0                   0.0   \n",
              "4                     0.0                   0.0                   0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  1.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  1.0   \n",
              "3                  1.0                  0.0                  0.0   \n",
              "4                  1.0                  0.0                  0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
              "0                  0.0                  0.0                  0.0   \n",
              "1                  0.0                  0.0                  0.0   \n",
              "2                  0.0                  0.0                  0.0   \n",
              "3                  0.0                  0.0                  0.0   \n",
              "4                  0.0                  0.0                  0.0   \n",
              "\n",
              "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
              "0                           0.0  ...                0.0   \n",
              "1                           0.0  ...                1.0   \n",
              "2                           1.0  ...                0.0   \n",
              "3                           1.0  ...                0.0   \n",
              "4                           0.0  ...                0.0   \n",
              "\n",
              "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                     0.0                       0.0                 0.0   \n",
              "1                     0.0                       0.0                 0.0   \n",
              "2                     0.0                       0.0                 0.0   \n",
              "3                     1.0                       0.0                 0.0   \n",
              "4                     0.0                       1.0                 0.0   \n",
              "\n",
              "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0               0.0                     0.0              0.0   \n",
              "1               0.0                     0.0              0.0   \n",
              "2               0.0                     0.0              0.0   \n",
              "3               0.0                     0.0              0.0   \n",
              "4               0.0                     0.0              0.0   \n",
              "\n",
              "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                0.0                       1.0                       0.0  \n",
              "1                0.0                       1.0                       0.0  \n",
              "2                0.0                       1.0                       0.0  \n",
              "3                0.0                       1.0                       0.0  \n",
              "4                0.0                       1.0                       0.0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bae33a5c-5b8e-48c7-9d1e-19c55cd19dfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>APPLICATION_TYPE_T8</th>\n",
              "      <th>AFFILIATION_CompanySponsored</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bae33a5c-5b8e-48c7-9d1e-19c55cd19dfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bae33a5c-5b8e-48c7-9d1e-19c55cd19dfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bae33a5c-5b8e-48c7-9d1e-19c55cd19dfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "application_df= application_df.merge(encode_df, left_index=True, right_index= True)\n",
        "#drop the column dont need dups\n",
        "application_df= application_df.drop(columns= application_cat)\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "yOqWmhIvimYl",
        "outputId": "75b87ec6-55d0-48a2-a6d3-fe9fde4aef80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                     0.0   \n",
              "1       1   108590              1                     0.0   \n",
              "2       1     5000              0                     0.0   \n",
              "3       1     6692              1                     0.0   \n",
              "4       1   142590              1                     0.0   \n",
              "\n",
              "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                   1.0                   0.0                  0.0   \n",
              "1                   0.0                   0.0                  1.0   \n",
              "2                   0.0                   0.0                  0.0   \n",
              "3                   0.0                   0.0                  1.0   \n",
              "4                   0.0                   0.0                  1.0   \n",
              "\n",
              "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                  0.0                  0.0                  0.0  ...   \n",
              "1                  0.0                  0.0                  0.0  ...   \n",
              "2                  0.0                  1.0                  0.0  ...   \n",
              "3                  0.0                  0.0                  0.0  ...   \n",
              "4                  0.0                  0.0                  0.0  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                0.0                     0.0                       0.0   \n",
              "1                1.0                     0.0                       0.0   \n",
              "2                0.0                     0.0                       0.0   \n",
              "3                0.0                     1.0                       0.0   \n",
              "4                0.0                     0.0                       1.0   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                 0.0               0.0                     0.0   \n",
              "1                 0.0               0.0                     0.0   \n",
              "2                 0.0               0.0                     0.0   \n",
              "3                 0.0               0.0                     0.0   \n",
              "4                 0.0               0.0                     0.0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0              0.0                0.0                       1.0   \n",
              "1              0.0                0.0                       1.0   \n",
              "2              0.0                0.0                       1.0   \n",
              "3              0.0                0.0                       1.0   \n",
              "4              0.0                0.0                       1.0   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                       0.0  \n",
              "1                       0.0  \n",
              "2                       0.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1adebf41-38f4-4db5-8edd-6db2c080b733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1adebf41-38f4-4db5-8edd-6db2c080b733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1adebf41-38f4-4db5-8edd-6db2c080b733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1adebf41-38f4-4db5-8edd-6db2c080b733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays- use IS_SUCCESSFUL\n",
        "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y=application_df.IS_SUCCESSFUL.values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
        "#testing it with another random_state\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "zYLufEulis4E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 1: Increased the neurons"
      ],
      "metadata": {
        "id": "N5mR56aLi4VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features= len(X_train_scaled[0])\n",
        "hidden_nodes_layer1= 120\n",
        "hidden_nodes_layer2=50\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add (tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atwdeUoKi1DG",
        "outputId": "5c568198-dbc0-40d4-dd96-3a358b92548c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 120)               4200      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                6050      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,301\n",
            "Trainable params: 10,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "# Train the model\n",
        "fit_model=nn.fit(X_train, y_train, epochs=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0429zpCi-LV",
        "outputId": "90dcb56a-e902-45c3-80b7-1723c93f818c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 43968.5234 - accuracy: 0.4955\n",
            "Epoch 2/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 32038.9062 - accuracy: 0.4915\n",
            "Epoch 3/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 35739.3281 - accuracy: 0.4979\n",
            "Epoch 4/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 29746.0156 - accuracy: 0.5025\n",
            "Epoch 5/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 7867.0117 - accuracy: 0.5071\n",
            "Epoch 6/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 19264.8008 - accuracy: 0.4893\n",
            "Epoch 7/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 14616.2100 - accuracy: 0.4993\n",
            "Epoch 8/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 3436.4531 - accuracy: 0.5106\n",
            "Epoch 9/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 9644.3008 - accuracy: 0.5007\n",
            "Epoch 10/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 2774.3818 - accuracy: 0.5112\n",
            "Epoch 11/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 1825.4019 - accuracy: 0.5261\n",
            "Epoch 12/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 88.7290 - accuracy: 0.5633\n",
            "Epoch 13/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6398 - accuracy: 0.6509\n",
            "Epoch 14/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.6415\n",
            "Epoch 15/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6318 - accuracy: 0.6608\n",
            "Epoch 16/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6289 - accuracy: 0.6630\n",
            "Epoch 17/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6273 - accuracy: 0.6643\n",
            "Epoch 18/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.6667\n",
            "Epoch 19/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6248 - accuracy: 0.6687\n",
            "Epoch 20/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.6698\n",
            "Epoch 21/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.6691\n",
            "Epoch 22/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6229 - accuracy: 0.6716\n",
            "Epoch 23/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6226 - accuracy: 0.6720\n",
            "Epoch 24/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.6745\n",
            "Epoch 25/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5879\n",
            "Epoch 26/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 27/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 28/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 29/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 30/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 31/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 32/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 33/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 34/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 35/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 36/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 37/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 38/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 39/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 40/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 41/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 42/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 43/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 44/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5315\n",
            "Epoch 45/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 46/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 47/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 48/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 49/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 50/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 51/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5305\n",
            "Epoch 52/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5321\n",
            "Epoch 53/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6915 - accuracy: 0.5312\n",
            "Epoch 54/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5312\n",
            "Epoch 55/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 56/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5311\n",
            "Epoch 57/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6917 - accuracy: 0.5312\n",
            "Epoch 58/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 59/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 60/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5317\n",
            "Epoch 61/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 62/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 63/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5314\n",
            "Epoch 64/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5317\n",
            "Epoch 65/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5315\n",
            "Epoch 66/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 67/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 68/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5306\n",
            "Epoch 69/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 70/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 71/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 72/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 73/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5312\n",
            "Epoch 74/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 75/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 76/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5314\n",
            "Epoch 77/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 78/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 79/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 80/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5313\n",
            "Epoch 81/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5304\n",
            "Epoch 82/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5316\n",
            "Epoch 83/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 84/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5321\n",
            "Epoch 85/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5312\n",
            "Epoch 86/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 87/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 88/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 89/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 90/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 91/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 92/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 93/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 94/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 95/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 96/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 97/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 98/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 99/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 100/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 101/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 102/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 103/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 104/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 105/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5307\n",
            "Epoch 106/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 107/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 108/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 109/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 110/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 111/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 112/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 113/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 114/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 115/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 116/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 117/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 118/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n",
            "Epoch 119/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6913 - accuracy: 0.5321\n",
            "Epoch 120/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "#improvement on the loss and accuracy!  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M3pyr0NjGaJ",
        "outputId": "aa52ee5d-f16c-4935-ae00-640ab1a56c0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.7883 - accuracy: 0.6745 - 444ms/epoch - 2ms/step\n",
            "Loss: 0.7883296012878418, Accuracy: 0.6745189428329468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 2: Additional hidden layers"
      ],
      "metadata": {
        "id": "UKgd3kDYkDz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features= len(X_train_scaled[0])\n",
        "hidden_nodes_layer1= 120\n",
        "hidden_nodes_layer2=50\n",
        "hidden_nodes_layer3=15\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add (tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s7aOqRSj16I",
        "outputId": "062de6d9-e9f3-4547-f611-9cfc53236027"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 120)               4200      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 50)                6050      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,851\n",
            "Trainable params: 12,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "# Train the model\n",
        "fit_model=nn.fit(X_train, y_train, epochs=135)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pOY4yIxkew1",
        "outputId": "1a2eefcf-d949-4d22-8165-3bbc73b47e7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/135\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 20575.7656 - accuracy: 0.4904\n",
            "Epoch 2/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 16011.8789 - accuracy: 0.4850\n",
            "Epoch 3/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 10844.0176 - accuracy: 0.4910\n",
            "Epoch 4/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 6152.8267 - accuracy: 0.4997\n",
            "Epoch 5/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 30376.2598 - accuracy: 0.5045\n",
            "Epoch 6/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 4278.6899 - accuracy: 0.5181\n",
            "Epoch 7/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.7705 - accuracy: 0.5321\n",
            "Epoch 8/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5321\n",
            "Epoch 9/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6915 - accuracy: 0.5321\n",
            "Epoch 10/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 11/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 12/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 13/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 14/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 15/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 16/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 17/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 18/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 19/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 20/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 21/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 22/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 23/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 24/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 25/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 26/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 27/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 28/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 29/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 30/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 31/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 32/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 33/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 34/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 35/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 36/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 37/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 38/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 39/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 40/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 41/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 42/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 43/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 44/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 45/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 46/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 47/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 48/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 49/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 50/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 51/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 52/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 53/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 54/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 55/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 56/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 57/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 58/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 59/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 60/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 61/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 62/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 63/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 64/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 65/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 66/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 67/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 68/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 69/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 70/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 71/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 72/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 73/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 74/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 75/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 76/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 77/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 78/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 79/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 80/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 81/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 82/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 83/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 84/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 85/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 86/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 87/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 88/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 89/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 90/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 91/135\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 92/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 93/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 94/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 95/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 96/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 97/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 98/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 99/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 100/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 101/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 102/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 103/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 104/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 105/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 106/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 107/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 108/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 109/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 110/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 111/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 112/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 113/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 114/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 115/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 116/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 117/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 118/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 119/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 120/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 121/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 122/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 123/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 124/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 125/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 126/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 127/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 128/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 129/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 130/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 131/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 132/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 133/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 134/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 135/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "#the additional layer didnt really improve anything  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA3KXB5Vkguc",
        "outputId": "372ce277-689c-4540-8aa8-9937cb18aabd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.7132 - accuracy: 0.5332 - 415ms/epoch - 2ms/step\n",
            "Loss: 0.7131916880607605, Accuracy: 0.5331778526306152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 3: Changing the activation function from relu to tanh "
      ],
      "metadata": {
        "id": "cTvuc8uJm30s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features= len(X_train_scaled[0])\n",
        "hidden_nodes_layer1= 120\n",
        "hidden_nodes_layer2=50\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='tanh'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='tanh'))\n",
        "\n",
        "# Output layer\n",
        "nn.add (tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pkkb1yIm3P2",
        "outputId": "5a0eb75a-5e42-4b14-8598-10caaa45fbf5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 120)               4200      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 50)                6050      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,301\n",
            "Trainable params: 10,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "# Train the model\n",
        "fit_model=nn.fit(X_train, y_train, epochs=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUkMpAvhnhKo",
        "outputId": "210fe87e-6fa1-4f7f-e5be-298b64148eca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6945 - accuracy: 0.5206\n",
            "Epoch 2/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5238\n",
            "Epoch 3/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5280\n",
            "Epoch 4/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5284\n",
            "Epoch 5/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5266\n",
            "Epoch 6/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5254\n",
            "Epoch 7/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5287\n",
            "Epoch 8/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5295\n",
            "Epoch 9/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5270\n",
            "Epoch 10/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6919 - accuracy: 0.5248\n",
            "Epoch 11/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5270\n",
            "Epoch 12/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5276\n",
            "Epoch 13/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5269\n",
            "Epoch 14/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5265\n",
            "Epoch 15/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5266\n",
            "Epoch 16/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5290\n",
            "Epoch 17/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5300\n",
            "Epoch 18/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5254\n",
            "Epoch 19/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5289\n",
            "Epoch 20/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5247\n",
            "Epoch 21/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5226\n",
            "Epoch 22/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5257\n",
            "Epoch 23/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5289\n",
            "Epoch 24/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5255\n",
            "Epoch 25/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5252\n",
            "Epoch 26/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5252\n",
            "Epoch 27/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5283\n",
            "Epoch 28/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5231\n",
            "Epoch 29/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5239\n",
            "Epoch 30/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5251\n",
            "Epoch 31/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5290\n",
            "Epoch 32/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5269\n",
            "Epoch 33/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5280\n",
            "Epoch 34/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5301\n",
            "Epoch 35/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5297\n",
            "Epoch 36/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5233\n",
            "Epoch 37/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5273\n",
            "Epoch 38/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5296\n",
            "Epoch 39/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5273\n",
            "Epoch 40/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5273\n",
            "Epoch 41/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5241\n",
            "Epoch 42/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5292\n",
            "Epoch 43/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5249\n",
            "Epoch 44/120\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6924 - accuracy: 0.5269\n",
            "Epoch 45/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6920 - accuracy: 0.5286\n",
            "Epoch 46/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6923 - accuracy: 0.5281\n",
            "Epoch 47/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5262\n",
            "Epoch 48/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5278\n",
            "Epoch 49/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5278\n",
            "Epoch 50/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5270\n",
            "Epoch 51/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5293\n",
            "Epoch 52/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5280\n",
            "Epoch 53/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5260\n",
            "Epoch 54/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5274\n",
            "Epoch 55/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5259\n",
            "Epoch 56/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5266\n",
            "Epoch 57/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5271\n",
            "Epoch 58/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5260\n",
            "Epoch 59/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5240\n",
            "Epoch 60/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5245\n",
            "Epoch 61/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5259\n",
            "Epoch 62/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5288\n",
            "Epoch 63/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5255\n",
            "Epoch 64/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5255\n",
            "Epoch 65/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5265\n",
            "Epoch 66/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5251\n",
            "Epoch 67/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5299\n",
            "Epoch 68/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5296\n",
            "Epoch 69/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5257\n",
            "Epoch 70/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5297\n",
            "Epoch 71/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5259\n",
            "Epoch 72/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5259\n",
            "Epoch 73/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5239\n",
            "Epoch 74/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5270\n",
            "Epoch 75/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5256\n",
            "Epoch 76/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5303\n",
            "Epoch 77/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5306\n",
            "Epoch 78/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6923 - accuracy: 0.5307\n",
            "Epoch 79/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5260\n",
            "Epoch 80/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5250\n",
            "Epoch 81/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5268\n",
            "Epoch 82/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5304\n",
            "Epoch 83/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5300\n",
            "Epoch 84/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5274\n",
            "Epoch 85/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5245\n",
            "Epoch 86/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5276\n",
            "Epoch 87/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5266\n",
            "Epoch 88/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5274\n",
            "Epoch 89/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5309\n",
            "Epoch 90/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5232\n",
            "Epoch 91/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5241\n",
            "Epoch 92/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5274\n",
            "Epoch 93/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5262\n",
            "Epoch 94/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5266\n",
            "Epoch 95/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5242\n",
            "Epoch 96/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5255\n",
            "Epoch 97/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5248\n",
            "Epoch 98/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5262\n",
            "Epoch 99/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5257\n",
            "Epoch 100/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5282\n",
            "Epoch 101/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5236\n",
            "Epoch 102/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5262\n",
            "Epoch 103/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6918 - accuracy: 0.5274\n",
            "Epoch 104/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5320\n",
            "Epoch 105/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5265\n",
            "Epoch 106/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5290\n",
            "Epoch 107/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6921 - accuracy: 0.5267\n",
            "Epoch 108/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6926 - accuracy: 0.5248\n",
            "Epoch 109/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6924 - accuracy: 0.5235\n",
            "Epoch 110/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5262\n",
            "Epoch 111/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5255\n",
            "Epoch 112/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6923 - accuracy: 0.5249\n",
            "Epoch 113/120\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.6923 - accuracy: 0.5282\n",
            "Epoch 114/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6925 - accuracy: 0.5268\n",
            "Epoch 115/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6922 - accuracy: 0.5282\n",
            "Epoch 116/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6920 - accuracy: 0.5290\n",
            "Epoch 117/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5262\n",
            "Epoch 118/120\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6922 - accuracy: 0.5258\n",
            "Epoch 119/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5294\n",
            "Epoch 120/120\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "#worst accuracy- tanh doesnt work well with this model "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nKdBeonnnh1",
        "outputId": "35b02dc4-738e-4f16-a06f-22b5a6553ce7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.7539 - accuracy: 0.3799 - 406ms/epoch - 2ms/step\n",
            "Loss: 0.7539176940917969, Accuracy: 0.3799417018890381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 4: decrease the value of the neurons"
      ],
      "metadata": {
        "id": "UuosnwMAoZC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features= len(X_train_scaled[0])\n",
        "hidden_nodes_layer1= 45\n",
        "hidden_nodes_layer2=15\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add (tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add (tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbc81au4oYaM",
        "outputId": "67950237-e679-4d03-aae7-3fb0a9ebafa3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 45)                1575      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 15)                690       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,281\n",
            "Trainable params: 2,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "# Train the model\n",
        "fit_model=nn.fit(X_train, y_train, epochs=135)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhoY-xK7oU20",
        "outputId": "09a6efc7-0ee6-406f-f802-aabb664b4e66"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 16261.9463 - accuracy: 0.5063\n",
            "Epoch 2/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 16538.9668 - accuracy: 0.4991\n",
            "Epoch 3/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 8127.7339 - accuracy: 0.4947\n",
            "Epoch 4/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 20238.5566 - accuracy: 0.4913\n",
            "Epoch 5/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 6244.9219 - accuracy: 0.5031\n",
            "Epoch 6/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 4840.3994 - accuracy: 0.5080\n",
            "Epoch 7/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 19068.5996 - accuracy: 0.5034\n",
            "Epoch 8/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 13061.5508 - accuracy: 0.5155\n",
            "Epoch 9/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 11612.0664 - accuracy: 0.5141\n",
            "Epoch 10/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 10220.7559 - accuracy: 0.5068\n",
            "Epoch 11/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 2637.1838 - accuracy: 0.5397\n",
            "Epoch 12/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 5949.4126 - accuracy: 0.5091\n",
            "Epoch 13/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 8522.8809 - accuracy: 0.5061\n",
            "Epoch 14/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 4379.8540 - accuracy: 0.5123\n",
            "Epoch 15/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 2284.2871 - accuracy: 0.5101\n",
            "Epoch 16/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 2492.7063 - accuracy: 0.5068\n",
            "Epoch 17/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 3346.4690 - accuracy: 0.5114\n",
            "Epoch 18/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 3290.2603 - accuracy: 0.4913\n",
            "Epoch 19/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 9152.6436 - accuracy: 0.5013\n",
            "Epoch 20/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 5247.9517 - accuracy: 0.5066\n",
            "Epoch 21/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 2927.6301 - accuracy: 0.5113\n",
            "Epoch 22/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 3313.4170 - accuracy: 0.5133\n",
            "Epoch 23/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 1770.4803 - accuracy: 0.5163\n",
            "Epoch 24/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 134.8867 - accuracy: 0.5185\n",
            "Epoch 25/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 240.5998 - accuracy: 0.5120\n",
            "Epoch 26/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 83.8744 - accuracy: 0.5409\n",
            "Epoch 27/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 28/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 29/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 30/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 31/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 32/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 33/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 34/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 35/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 36/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 37/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 38/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 39/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 40/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 41/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 42/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 43/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 44/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 45/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 46/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 47/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 48/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 49/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 50/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 51/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 52/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 53/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 54/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 55/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 56/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 57/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 58/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 59/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 60/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 61/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 62/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 63/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 64/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 65/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 66/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 67/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 68/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 69/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 70/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 71/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 72/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 73/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 74/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 75/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 76/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 77/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 78/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 79/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 80/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 81/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 82/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 83/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 84/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 85/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 86/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 87/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 88/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 89/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 90/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 91/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 92/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 93/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 94/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 95/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 96/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 97/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 98/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 99/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5321\n",
            "Epoch 100/135\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 101/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 102/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 103/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 104/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 105/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 106/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 107/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 108/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 109/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 110/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 111/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 112/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 113/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 114/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 115/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 116/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 117/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
            "Epoch 118/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 119/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 120/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 121/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 122/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 123/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 124/135\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 125/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 126/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 127/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 128/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 129/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 130/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 131/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 132/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 133/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 134/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
            "Epoch 135/135\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "#the removal of tanh and decrease in nodes improved the accuracy significantly but the loss is very high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK643S-VoUBC",
        "outputId": "abea0e1e-b06a-4753-e46f-6490fbb98acc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 1.4435 - accuracy: 0.7058 - 408ms/epoch - 2ms/step\n",
            "Loss: 1.4435189962387085, Accuracy: 0.7057725787162781\n"
          ]
        }
      ]
    }
  ]
}